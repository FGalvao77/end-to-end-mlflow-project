# ‚úÖ MLflow Docker Compose Integration - Solu√ß√£o Implementada

## Problema Original
```
ConnectionRefusedError: [Errno 111] Connection refused
MissingConfigException: Yaml file '/mlruns/artifacts/models/m-.../metadata.yaml' does not exist
Permission denied: '/mlruns'
```

Os experimentos n√£o estavam sendo persistidos no Docker Compose MLflow.

---

## Raiz do Problema

### 1. **Configura√ß√£o de Volume Incorreta** ‚ùå ANTES
```yaml
volumes:
  - /home/fernandogalvao/Documentos/my-projects/.../mlruns:/mlruns
```
- Volume mapeava caminho absoluto longo do host
- Paths inconsistentes entre client e server
- Experi√™ncias com artifact_location apontando para caminhos incorretos

### 2. **URI de Backend Incorreta**
```
MLFLOW_ARTIFACT_ROOT: file:///home/fernandogalvao/.../mlruns/artifacts
```
- Path absoluto do host em vez de path do container
- Criava diret√≥rio `/artifacts` na raiz, n√£o em `/mlruns/artifacts`

### 3. **Client-Server Path Mismatch**
Quando o cliente (host Python) tenta fazer `mlflow.sklearn.log_model()`:
- MLflow server v√™ `/mlruns/` (path no container)
- Cliente tenta acessar `/mlruns` (n√£o existe no host!)
- Resultado: `Permission denied: '/mlruns'`

---

## Solu√ß√£o Implementada ‚úÖ

### 1. **Docker Compose Corrigido**

**Arquivo:** `src/mlops_project/docker-compose.mlflow.yml`

```yaml
volumes:
  - ./mlruns:/mlruns:rw           # ‚úÖ Caminho relativo simples + permiss√£o rw
  - .:/workspace:rw                # ‚úÖ Permite training dentro do container

environment:
  - MLFLOW_BACKEND_STORE_URI=sqlite:////mlruns/mlflow.db  # ‚úÖ Uri absoluta do container
  - MLFLOW_DEFAULT_ARTIFACT_ROOT=file:///mlruns/artifacts # ‚úÖ Path consistente

healthcheck:                         # ‚úÖ Verifica sa√∫de do servidor
  test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
```

### 2. **Training Service Opcional**

Adicionado servi√ßo `training` que roda **dentro do container**:
```bash
# Executa training no container (mesma path context que o MLflow server)
docker compose --profile training up training
```

### 3. **Melhor Handling de Erros**

**Arquivo:** `src/mlops_project/train.py`

Mensagens agora indicam exatamente o problema e solu√ß√µes:

```python
if is_remote:
    print(f"‚ö†Ô∏è  WARNING: Cannot log model to remote MLflow server")
    print(f"   Error: Permission denied: {perm_err}")
    print(f"   Model was trained successfully at: {exported}")
    print(f"\n   To fix this:")
    print(f"   1. Run training INSIDE container: docker compose ... exec training ...")
    print(f"   2. Use S3-compatible artifact storage")
    print(f"   3. Use file:// tracking URI instead")
```

### 4. **Novo Arquivo de Utilit√°rios**

**Arquivo:** `src/mlops_project/mlflow_utils.py`

Fun√ß√µes auxiliares para detectar se est√° usando servidor remoto e ajustar comportamento.

### 5. **Script Shell Helper**

**Arquivo:** `mlflow.sh`

Comandos convenientes:
```bash
./mlflow.sh server              # Inicia servidor MLflow
./mlflow.sh train-host          # Train no host (com avisos de permission)
./mlflow.sh train-container     # Train no container (RECOMENDADO)
./mlflow.sh ui                  # Abre UI no browser
./mlflow.sh stop                # Para containers
./mlflow.sh clean               # Limpa artifacts
```

---

## Como Usar Agora

### ‚úÖ Op√ß√£o 1: Training Dentro do Container (Sem Erros de Permiss√£o)

```bash
# Inicia servidor MLflow
export DOCKER_API_VERSION=1.44
docker compose -f src/mlops_project/docker-compose.mlflow.yml up -d

# Aguarda 30-40 segundos para servidor iniciar completamente

# Training dentro do container (mesmos paths, sem problema)
docker compose -f src/mlops_project/docker-compose.mlflow.yml exec training \
  python train.py

# Ou use o script helper:
./mlflow.sh train-container
```

### ‚úÖ Op√ß√£o 2: Training Local (File-Based, Sem Server)

```bash
# Sem servidor - usa store local
.venv/bin/python src/mlops_project/train.py

# Ver experimentos na UI local
mlflow ui
```

### ‚úÖ Op√ß√£o 3: Training no Host + Server (Com Avisos Benignos)

```bash
export DOCKER_API_VERSION=1.44
docker compose -f src/mlops_project/docker-compose.mlflow.yml up -d

# Training no host com tracking remoto
export MLFLOW_TRACKING_URI=http://127.0.0.1:5000
.venv/bin/python src/mlops_project/train.py

# ‚ö†Ô∏è Pode mostrar WARNING sobre permission, mas:
# ‚úì M√©tricas e parameters s√£o logados com sucesso
# ‚úì Experiments s√£o criados e persistem
# ‚úì Apenas model artifacts n√£o s√£o salvos no MLflow (j√° est√£o locais)
```

---

## Status Verificado

| Componente | Status | Notas |
|-----------|--------|-------|
| **MLflow Server** | ‚úÖ Rodando | Container saud√°vel na porta 5000 |
| **DB SQLite** | ‚úÖ Criando | `mlruns/mlflow.db` criado e funcional |
| **Experiments** | ‚úÖ Persistindo | Vis√≠veis na UI `http://127.0.0.1:5000` |
| **Runs** | ‚úÖ Logando | M√©tricas e tags salvos |
| **Model Logging** | ‚ö†Ô∏è Aviso | Mensagem clara + modelo ainda treinado com sucesso |
| **Training Script** | ‚úÖ Robusto | N√£o quebra com erros de MLflow |

---

## Pr√≥ximas Melhorias (Opcional)

### Para Produ√ß√£o:
1. **PostgreSQL** em vez de SQLite
   ```yaml
   MLFLOW_BACKEND_STORE_URI: postgresql://user:pass@postgres:5432/mlflow_db
   ```

2. **S3 ou MinIO** para artifacts
   ```bash
   export MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://my-bucket/artifacts
   export AWS_ACCESS_KEY_ID=...
   export AWS_SECRET_ACCESS_KEY=...
   ```

3. **Kubernetes Deployment**
   - Helm charts ou manifests para produ√ß√£o
   - Scaling autom√°tico de training jobs

---

## üö® Troubleshooting

### "N√£o consigo acessar `http://0.0.0.0:5000`"

‚ùå **Errado:**
```
http://0.0.0.0:5000     # Conex√£o recusada - 0.0.0.0 s√≥ funciona em servidores
```

‚úÖ **Correto:**
```bash
# Para acessar via browser:
http://127.0.0.1:5000   # Localhost IP (recomendado)
http://localhost:5000   # Hostname

# Para training script acessar MLflow:
export MLFLOW_TRACKING_URI=http://127.0.0.1:5000  # Do host
export MLFLOW_TRACKING_URI=http://mlflow:5000     # Do container

# Do training service no Docker:
export MLFLOW_TRACKING_URI=http://mlflow:5000     # Via DNS do Docker
```

**Por qu√™?** `0.0.0.0` √© um endere√ßo especial que significa "escuta em TODAS as interfaces de rede". Funciona para **servidores**, mas clientes n√£o conseguem se conectar nele. Use `127.0.0.1` (localhost) ou o hostname da m√°quina.

---

### "Experimentos aparecem mas sem hist√≥rico temporal"

Se os experimentos existem mas voc√™ n√£o v√™ gr√°ficos de m√©tricas ao longo do tempo:

1. **Verifique se h√° runs logados:**
   ```bash
   # Acesse a UI e cls em um experimento
   # Deve mostrar "Runs" na aba esquerda
   ```

2. **Verifique se m√©tricas foram logadas:**
   ```bash
   sqlite3 src/mlops_project/mlruns/mlflow.db \
     "SELECT COUNT(*) FROM metrics;"
   ```

3. **Status do banco de dados:**
   ```bash
   # Se corrupto, limpe e recrie
   rm -rf src/mlops_project/mlruns
   mkdir -p src/mlops_project/mlruns/artifacts
   
   # Reinicie o server
   docker compose -f src/mlops_project/docker-compose.mlflow.yml restart mlflow
   ```

---

```bash
# Ver status dos containers
docker compose -f src/mlops_project/docker-compose.mlflow.yml ps

# Ver logs do MLflow
docker compose -f src/mlops_project/docker-compose.mlflow.yml logs --tail=100 mlflow

# Limpar tudo (cuidado!)
rm -rf src/mlops_project/mlruns
docker compose -f src/mlops_project/docker-compose.mlflow.yml down -v

# Inspecionar DB
sqlite3 src/mlops_project/mlruns/mlflow.db "SELECT experiment_id, name FROM experiments;"
```

---

## Resumo Final

‚úÖ **Problema resolvido** ‚Äì Experiments agora persistem corretamente  
‚úÖ **Solu√ß√£o elegante** ‚Äì Training pode rodar host ou container conforme prefer√™ncia  
‚úÖ **Mensagens claras** ‚Äì Usu√°rio entende exatamente o que est√° acontecimento  
‚úÖ **Pronto para produ√ß√£o** ‚Äì Estrutura pronta para escalar (S3, Postgres, K8s)  

O projeto est√° **operacional e robusto!** üöÄ
