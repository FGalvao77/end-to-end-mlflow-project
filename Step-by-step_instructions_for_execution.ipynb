{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71e331f",
   "metadata": {},
   "source": [
    "# Passo a Passo de Implementação do Projeto\n",
    "\n",
    "## 0) Visão geral do que já existe\n",
    "\n",
    "- **Treino**: `train.py` treina um `RandomForest` dentro de um `Pipeline` com `StandardScaler`, calcula métricas, salva artefatos em `artifacts/model` e (se disponível) registra no MLflow.  \n",
    "- **Config**: `configs.yaml` define `test_size`, `random_state`, hiperparâmetros e pasta de export.  \n",
    "- **Dados**: `data_prep.py` usa `load_breast_cancer` do scikit-learn e faz split estratificado.  \n",
    "- **Util**: `utils.py` carrega YAML (a função `load_config`).  \n",
    "- **Tracking**: `docker-compose.mlflow.yml` sobe um MLflow Server file-based na porta 5000.  \n",
    "- **Kubernetes**: `deployment.yaml` define Deployment/Service para a imagem `projeto10-model:latest` (porta 8000, `/ping`, NodePort 30080).  \n",
    "\n",
    "---\n",
    "\n",
    "## 1) Preparar ambiente local\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate        # Windows: .venv\\Scripts\\activate\n",
    "python -m pip install -U pip\n",
    "\n",
    "# instalar dependências do projeto\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# (opcional) MLflow p/ tracking/serving\n",
    "pip install mlflow\n",
    "```\n",
    "\n",
    "> O script principal chama `load_config('src/mlops_project/configs.yaml')` e usa imports relativos (`from .utils ...`), então vamos executar como **módulo** a partir de `src/`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Conferir e ajustar `configs.yaml`\n",
    "\n",
    "Abra `src/mlops_project/configs.yaml` e ajuste conforme sua necessidade (já vem com valores padrão):  \n",
    "- `test_size`, `random_state`  \n",
    "- `model.params` (ex.: `n_estimators`, `max_depth`, `n_jobs`)  \n",
    "- `paths.exported_model_dir` (ex.: `artifacts/model`)  \n",
    "\n",
    "---\n",
    "\n",
    "## 3) Executar o treino e gerar artefatos\n",
    "\n",
    "O dataset vem de `load_breast_cancer(as_frame=True)` e o split é estratificado.  \n",
    "\n",
    "Da raiz do repositório:\n",
    "\n",
    "```bash\n",
    "cd projeto10-mlops-slim-mlflow-fastapi-optional/core/src\n",
    "python -m mlops_project.train\n",
    "\n",
    "```\n",
    "\n",
    "Fluxo de execução:\n",
    "- Carrega config (`utils.load_config`) e dados (`data_prep.load_dataset`).  \n",
    "- Split treino/teste com `test_size` e `random_state` do YAML.  \n",
    "- Monta `Pipeline([('scaler', StandardScaler(with_mean=False)), ('clf', RandomForestClassifier(**params))])`, treina, prediz e calcula **accuracy**, **precision**, **recall**, **f1**, imprimindo também o `classification_report`.  \n",
    "- Cria pasta `artifacts/model` (ou a do YAML) e salva `model.joblib`.  \n",
    "- Se o MLflow estiver instalado/importado, salva um **MLflow Model** no mesmo diretório e registra **parâmetros/métricas/model** no servidor (caso `MLFLOW_TRACKING_URI` esteja configurado).  \n",
    "\n",
    "---\n",
    "\n",
    "## 4) Subir o MLflow Tracking\n",
    "\n",
    "Vídeo como instalar Docker e Docker compose:\n",
    "\n",
    "https://www.youtube.com/watch?v=05YN8F8ajBc&t=10s  (no windows)\n",
    "\n",
    "https://www.youtube.com/watch?v=h27ZVQIh7Ro (docker compose no Linux)\n",
    "\n",
    "https://www.youtube.com/watch?v=Gpal5KsSHMQ&t=1s (docker no Linux)\n",
    "\n",
    "Suba o servidor com o compose que você já tem:\n",
    "\n",
    "```bash\n",
    "cd projeto10-mlops-slim-mlflow-fastapi-optional/core                                               \n",
    "docker compose -f docker-compose.yml up -d                                                                                      \n",
    " \n",
    " #UI em http://localhost:5000\n",
    "```\n",
    "\n",
    "No terminal onde você vai treinar, aponte o client para o servidor e (opcional) defina o nome do experimento:\n",
    "\n",
    "```bash\n",
    "export MLFLOW_TRACKING_URI=http://127.0.0.1:5000\n",
    "export MLFLOW_EXPERIMENT_NAME=Projeto10_MLOps\n",
    "```\n",
    "\n",
    "> Reexecute o **passo 3** para registrar runs, parâmetros, métricas e o modelo no MLflow. O `train.py` já está preparado para isso.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Servir o modelo localmente (MLflow Models Serve)\n",
    "\n",
    "Como o `train.py` salva um **MLflow Model** dentro da pasta de export, você pode servir direto dela:\n",
    "\n",
    "```bash\n",
    "mlflow models serve   -m artifacts/model   -p 8000 --host 0.0.0.0 --no-conda\n",
    "```\n",
    "\n",
    "### Testes rápidos\n",
    "\n",
    "```bash\n",
    "# healthcheck (compatível com /ping do seu manifest)\n",
    "curl -s http://127.0.0.1:8000/ping\n",
    "\n",
    "# inferência\n",
    "curl -X POST http://127.0.0.1:8000/invocations \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"dataframe_split\": {\n",
    "      \"columns\": [\n",
    "        \"mean radius\",\"mean texture\",\"mean perimeter\",\"mean area\",\"mean smoothness\",\n",
    "        \"mean compactness\",\"mean concavity\",\"mean concave points\",\"mean symmetry\",\"mean fractal dimension\",\n",
    "        \"radius error\",\"texture error\",\"perimeter error\",\"area error\",\"smoothness error\",\n",
    "        \"compactness error\",\"concavity error\",\"concave points error\",\"symmetry error\",\"fractal dimension error\",\n",
    "        \"worst radius\",\"worst texture\",\"worst perimeter\",\"worst area\",\"worst smoothness\",\n",
    "        \"worst compactness\",\"worst concavity\",\"worst concave points\",\"worst symmetry\",\"worst fractal dimension\"\n",
    "      ],\n",
    "      \"data\": [[\n",
    "        14.0,20.0,90.0,600.0,0.10,\n",
    "        0.15,0.12,0.07,0.18,0.06,\n",
    "        0.4,1.2,3.0,40.0,0.01,\n",
    "        0.02,0.03,0.02,0.03,0.004,\n",
    "        16.5,27.0,110.0,850.0,0.13,\n",
    "        0.25,0.22,0.12,0.24,0.08\n",
    "      ]]\n",
    "    }\n",
    "  }'\n",
    "'\n",
    "```\n",
    "\n",
    "> Dica: se preferir, salve o MLflow Model em um **subdiretório** (ex.: `artifacts/model/mlflow_model`) para não misturar com o `model.joblib`.\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Empacotar a aplicação em Docker\n",
    "\n",
    "A imagem esperada pelo seu `Deployment` do K8s se chama **`projeto10-model:latest`** e expõe a **porta 8000** com um endpoint **`/ping`**.\n",
    "\n",
    "Construa a imagem com seu `Dockerfile`:\n",
    "\n",
    "```bash\n",
    "docker build -t projeto10-model:latest .\n",
    "```\n",
    "\n",
    "Teste localmente:\n",
    "\n",
    "```bash\n",
    "docker run --rm -p 8000:8000 projeto10-model:latest\n",
    "curl -s http://127.0.0.1:8000/ping\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Publicar no Kubernetes\n",
    "\n",
    "Aplique os manifests que você já possui:\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=mi_aotXDMR8 (como instalar Kubernetes - kubectl)\n",
    "\n",
    "```bash\n",
    "kubectl apply -f projeto10-mlops-slim-mlflow-fastapi-optional/core/k8s/deployment.yaml\n",
    "kubectl get pods\n",
    "kubectl get svc\n",
    "kubectl get deploy projeto10-model\n",
    "kubectl rollout status deploy/projeto10-model\n",
    "kubectl get pods -l app=projeto10-model -o wide\n",
    "kubectl logs -l app=projeto10-model --tail=100\n",
    "\n",
    "```\n",
    "\n",
    "- **Deployment**: 2 réplicas, `image: projeto10-model:latest`, probes em `/ping` na porta 8000.  \n",
    "- **Service**: tipo **NodePort**, mapeando `:80 -> 8000` e expondo **30080** no nó.  \n",
    "\n",
    "### Testes\n",
    "\n",
    "```bash\n",
    "# se for NodePort e você está no mesmo nó (minikube/kind):\n",
    "curl -s http://127.0.0.1:30080/ping\n",
    "\n",
    "# ou faça port-forward\n",
    "kubectl port-forward svc/projeto10-model-svc 8080:80\n",
    "curl -s http://127.0.0.1:8080/ping\n",
    "\n",
    "# inferência (mesmo payload do passo 5)\n",
    "curl -X POST http://127.0.0.1:8080/invocations   -H \"Content-Type: application/json\"   -d '{\"dataframe_split\":{\"columns\":[\"mean radius\",\"mean texture\",\"mean perimeter\"],\"data\":[[14.0,20.0,90.0]]}}'\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
